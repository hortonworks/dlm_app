#Application configuration

#dp-keystore settings
dp.keystore.path=${PWD}/dp-build/shared/dp-keystore.jceks
dp.keystore.password=changeit

# Data plane creates its own store in the base directory
dp.services.keystore.base.path=${HOME}
dp.services.keystore.path=".dp_keystore"
dp.services.keystore.name="dp_certs_store"
dp.services.keystore.pass="P92[W%CP#d7g@^E8"
dp.services.keystore.removeOnExit=false

dp.services.ssl.config {
  disable.hostname.verification = false
}

dp.services.db {
  service.uri = "http://localhost:9005"
  service.path = "/service/db"
}

dp.service.hdinsight {
  auth.status = 401
  auth.response.message = "Probable HD-Insight cluster, Basic authentication detected"
  auth.challenge.contentType="text/html"
  auth.challenge.wwwAuthenticate="Basic realm=HDInsight"
}

dp.service.ambari {
  api.version = "/api/v1"
  cluster.api.prefix = "/api/v1/clusters"
  stack.api.prefix = "/api/v1/stacks"
  status.check.timeout.secs = 19

  # Set this to true if Ambari+HDP services are all on the same node
  # Underlying services will default to using the host/ip provided as the Ambari URL
  single.node.cluster=false

}

  # in Seconds
  dp.services.ws.client.requestTimeout.mins = 4

  # in Seconds
  dp.services.cluster.sync.start.secs = 10
  # in Minutes
  dp.services.cluster.sync.interval.mins = 5
  #Bind address for server
  dp.services.cluster.http.host = "0.0.0.0"
  #Port for server
  dp.services.cluster.http.port = 9009

  #Time to cache the API for the cluster
  dp.services.cluster.http.atlas.api.cache.secs = 3600

  # Time to memoize the URL supplier for each cluster
  dp.services.cluster.atlas.proxy.cache.expiry.secs = 86400

  #Time to expire the cached Atlas Api client
  dp.services.cluster.http.atlas.token.cache.secs = 3600

  dp.services.cluster.knox.token.cache.expiry.secs = 3600

  #How long before token expiry must the token cache key be invalidated - in seconds
  dp.services.cluster.knox.token.cache.removal.time = 3

  #Make this false to stop running jobs
  dp.services.cluster.run.jobs = false

  #Http client/server settings
  akka.http.server.request-timeout=60s
  akka.http.client.connecting-timeout=60s

  dp.services.hdp.proxy {

    host = "0.0.0.0"
    port = "9010"
    consul {
      #unique name
      serviceId = "hdp_proxy_01"
      #common name across instances
      serviceName = "hdp_proxy"
      service.tags = ["cluster-proxy-service"]
      service.port = 9010
      client.connect.failure.retry.secs = 5
      host = "localhost"
      port = 8500
    }

    #Only these services will be allowed to use the knox gateway , for all other services
    # the proxy will use the target URL specified in the header
    services=["webhdfs","templeton"]

  }


  dp.services.atlas {

    atlas.common.attributes = [
      {"name": "owner", "dataType": "string"},
      {"name": "name", "dataType": "string"},
      {"name": "db.name", "dataType": "string"},
      {"name": "tag", "dataType": "tag"}
    ]

    #Types to be accepted
    hive.accepted.types = ["string", "int", "long", "boolean", "date"]

    hive.search.query.base = "hive_table"

    lower.case.queries = false

    filter.deleted.entities = true

  }


  #there is no good way to find these out ,
  # it is assumed that these values will be used by convention
  dp.services.knox {

    # Name for the token topology
    token.topology="token"

    #Name of the dp sso topology, pointed to by the token
    token.target.topology="sandbox"

    #Should this service instance expect a sperate knox config group
    # ITS IMPORTANT THAT ALL SERVICE INSTANCES (IN HA) HAVE THE SAME VALUE FOR THIS CONFIGURATION
    token.expect.separate.config=false

    #Name of the config group
    token.config.group.name="dataplane"

    #Which mechanism should be used for inferring the additional config group and the final knox URL
    #if true then ambari credentials are used, if false then knox url is expected
    token.infer.endpoint.using.credentials=true

    #Name of the gateway path eg: https://ip:port/<gateway.name>
    gateway.name = "gateway"

    #Set to ture if gateway name must be inferred from the provider URL
    infer.gateway.name=true


  }

  DPSPlatform.credential {
    ambari {
      username = "admin"
      password = "admin"
    }
    atlas {
      username = "admin"
      password = "admin"
    }
    ranger {
      username = "admin"
      password = "admin"
    }
  }

  consul {
    #unique name
    serviceId = "clusters_01"
    #common name across instances
    serviceName = "clusters"
    service.tags = ["cluster-service"]
    service.port = 9009
    client.connect.failure.retry.secs = 5
    host = "localhost"
    port = 8500
  }

  gateway {
    ssl.enabled = false
    refresh.servers.secs = 60
  }

  atlas.query.records.default {
    limit = 10000
    offset = 0
  }

dp.certificate {
  query.timeout = 30 seconds
}