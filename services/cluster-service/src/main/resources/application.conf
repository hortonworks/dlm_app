#Application configuration

# Data plane creates its own store in the base directory
dp.services.keystore.base.path=${HOME}
dp.services.keystore.path=".dp_keystore"
dp.services.keystore.name="dp_certs_store"
dp.services.keystore.pass="P92[W%CP#d7g@^E8"
dp.services.keystore.removeOnExit=false

dp.services.ssl.config {
  disable.hostname.verification = false
}

dp.services.db {
  service.uri = "http://localhost:9005"
  service.path = "/api/db"
}

dp.service.ambari.cluster.api.prefix = "/api/v1/clusters"
dp.service.ambari.status.check.timeout.secs = 19

# in Seconds
dp.services.cluster.sync.start.secs = 10
# in Minutes
dp.services.cluster.sync.interval.mins = 5
#Bind address for server
dp.services.cluster.http.host = "0.0.0.0"
#Port for server
dp.services.cluster.http.port = 9009

#Time to cache the API for the cluster
dp.services.cluster.http.atlas.api.cache.secs = 3600

# Time to memoize the URL supplier for each cluster
dp.services.cluster.atlas.proxy.cache.expiry.secs = 86400

#Time to expire the cached Atlas Api client
dp.services.cluster.http.atlas.token.cache.secs = 3600

dp.services.cluster.knox.token.cache.expiry.secs = 3600

#How long before token expiry must the token cache key be invalidated - in seconds
dp.services.cluster.knox.token.cache.removal.time = 3

#Make this false to stop running jobs
dp.services.cluster.run.jobs = false

#Atlas enpoints

dp.services.hdp.proxy {

  host = "0.0.0.0"
  port = "9010"
  consul {
    #unique name
    serviceId = "hdp_proxy_01"
    #common name across instances
    serviceName = "hdp_proxy"
    service.tags = ["cluster-proxy-service"]
    service.port = 9010
    client.connect.failure.retry.secs = 5
    host = "localhost"
    port = 8500
  }

  #Only these services will be allowed to use the knox gateway , for all other services
  # the proxy will use the target URL specified in the header
  services=["webhdfs","templeton"]

}


dp.services.atlas {

  atlas.common.attributes = [{"name": "owner", "dataType": "string"},
    {"name": "name", "dataType": "string"},
    {"name": "db.name", "dataType": "string"},
    {"name": "tag", "dataType": "tag"}]

  #Types to be accepted
  hive.accepted.types = ["string", "int", "long", "boolean", "date"]

  hive.search.query.base = "hive_table"

}


#there is no good way to find these out ,
# it is assumed that these values will be used by convention
dp.services.knox {

  # Name for the token topology
  token.topology="token"

  #Name of the dp sso topology, pointed to by the token
  token.target.topology="sandbox"

  #Should this service instance expect a sperate knox config group
  # ITS IMPORTANT THAT ALL SERVICE INSTANCES (IN HA) HAVE THE SAME VALUE FOR THIS CONFIGURATION
  token.expect.separate.config=false

  #Name of the config group
  token.config.group.name="dataplane"

  #Which mechanism should be used for inferring the additional config group and the final knox URL
  #if true then ambari credentials are used, if false then knox url is expected
  token.infer.endpoint.using.credentials=true


}

consul {
  #unique name
  serviceId = "clusters_01"
  #common name across instances
  serviceName = "clusters"
  service.tags = ["cluster-service"]
  service.port = 9009
  client.connect.failure.retry.secs = 5
  host = "localhost"
  port = 8500
}

gateway {
  ssl.enabled = false
  refresh.servers.secs = 60
}

